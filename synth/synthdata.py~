import numpy as np
import math
import matplotlib.pyplot as plt
from scipy.interpolate import UnivariateSpline as UVS
from scipy.interpolate import interp1d



#=--------------------------------------------------=#
#==================INTERPOLATION=====================#
#=--------------------------------------------------=#
#interp takes x and y data and desired x points
#returns linearally interpolated y desired points
#extrapolates off either end of x data using the
#slope of the first and last sets of data points given.
def interp(x_DESIRED,x_DATA,y_DATA):
  y_DESIRED = zeros(length(x_DESIRED))
  index_DATA = linspace(1,length(x_DATA)-1,length(x_DATA)-1)
  index_DESIRED = [1:length(x_DESIRED)]
  #println([1:length(x_DESIRED)])
  #println(index_DESIRED)
  minx = minimum(x_DATA)
  maxx = maximum(x_DATA)
  for i in index_DESIRED:
    yset=0
    y_NEW =0
    for y in index_DATA:
      if yset ==0 && x_DESIRED[i] > x_DATA[y] && x_DESIRED[i] < x_DATA[y+1]  y < (length(index_DATA)-1) && i < (length(index_DATA)-1)
        rise = y_DATA[y+1]-y_DATA[y]
        run = x_DATA[y+1]-x_DATA[y]
        slope = rise / run
        y_change = slope*(x_DESIRED[i]-x_DATA[y])
        y_NEW = y_DATA[y]+y_change
        yset = 1
      elseif yset ==0 && x_DESIRED[i] < minx: #EXTRAPOLATION DOWNWARD
        #println("EXTRAP LOW!!")
        rise =y_DATA[2]-y_DATA[1]
        run = x_DATA[2]-x_DATA[1]
        first_slope= rise / run
        y_change = first_slope*(x_DATA[1]-x_DESIRED[i])
        y_NEW = y_DATA[1]-y_change
        yset = 1
      elseif yset ==0 && x_DESIRED[i] > maxx: #EXTRAPOLATION UPWARD
        #println("EXTRAP HIGH!!")
        rise=y_DATA[length(y_DATA)]-y_DATA[length(y_DATA)-1]
        run = x_DATA[length(x_DATA)]-x_DATA[length(x_DATA)-1]
        last_slope = rise / run
        y_change = last_slope*(x_DESIRED[i]-x_DATA[length(x_DATA)])
        y_NEW = y_DATA[length(y_DATA)]+ y_change
        yset = 1
      y_DESIRED[i] = y_NEW
  return y_DESIRED #This is the returned value. In Julia, return statements are not required.




def Model(X,ICF):
	L = len(ICF)
	MF=np.zeros((L),dtype='float')
	for i in range(0,L):
		MF[i]=np.sum(X*ICF[i,:])
	print 'Model: ',MF	
	return MF

def convolve(tdf_values,data_flux):
		val = len(data_flux)
		model_flux = np.empty(val)
		for idate in range(0,val):
			model_flux[idate] = np.sum(tdf_values*data_flux[idate])
		return model_flux

#TDF function from Blandford and McKee
def RAN(t,r):
	temp = np.empty([len(t)])
	for i in range(0,len(t)):
		if t[i] > 0 and t[i] <= (2.0*r):
			temp[i] = t[i]/(2.0*r)+np.log(2.0)
		elif t[i] > (2.0*r) and t[i] <= (4.0*r):
			temp[i] = 2.0 - t[i]/(2.0*r)+np.log(4.0*r/t[i])
		else:
			temp[i]=0
		#print 't: ', t[i], 'psi: ', temp[i]
	return 1.0/(2.0*r)*temp

'''IMPORT DATA FILES'''
#inputfile = '../Ver1/tdfL.txt'
#tdfL = np.loadtxt(open(inputfile,'rb'),delimiter=' ',skiprows=0)
#tdfL=tdfL[330]

inputfile = '../data/rvm_fluxes.csv'
rvm_spectra_flux = np.loadtxt(open(inputfile,'rb'),delimiter=',',skiprows=0)
#print 'Flux Array: ',rvm_spectra_flux.shape
spectra_scale=1.0e0
rvm_spectra_flux=rvm_spectra_flux*spectra_scale
#print rvm_spectra_flux.shape

inputfile = '../data/rvm_fluxes.csv'
data_flux = np.loadtxt(open(inputfile,'rb'),delimiter=',',skiprows=0)
#print('Flux Array: ',data_errflux.shape)
#nlines = len(data_errflux) # length first axis

inputfile = '../data/rvm_errfluxes.csv'
data_errflux = np.loadtxt(open(inputfile,'rb'),delimiter=',',skiprows=0)
#print('Error Flux Array: ',data_errflux.shape)
#nlines = len(data_errflux) # length first axis

inputfile = '../data/rvm_wavelengths.csv'
rvm_spectra_lam = np.loadtxt(open(inputfile,'rb'),delimiter=',',skiprows=0)
#print 'lam: ',len(rvm_spectra_lam)

inputfile = '../data/rvm_dates.csv'
rvm_spectra_date = np.loadtxt(open(inputfile,'rb'),delimiter=',',skiprows=0)
ndataperline = len(rvm_spectra_date)
#print 'date: ',len(rvm_spectra_date)

inputfile = '../data/arp151.b.dat'
data = np.loadtxt(open(inputfile,'rb'),delimiter=' ',skiprows=0)
continuum_date = data[:,0]
continuum_scale = 1.0e0
continuum_flux = data[:,1]*continuum_scale

inputfile = '../data/arp151.b.dat'
data = np.loadtxt(open(inputfile,'rb'),delimiter=' ',skiprows=0)
continuum_date = data[:,0]
continuum_scale = 1.0
continuum_flux = data[:,1]*continuum_scale
av = np.mean(continuum_flux)
#print 'average: ', av
#print 'continuum flux: ', continuum_flux
ax = np.max(continuum_flux)
continuum_errflux = data[:,2]

#print('cont: ', data.shape)
'''DONE IMPORTING DATA FILES'''

'''----------------------------------------------------'''
'''===================================================='''
'''----------------------------------------------------'''
tau = 50
c = 1.0
r = 15.0
tau = np.linspace(0,20,50)
Psi = RAN(tau,r)	#TDF from Blanford & McKee
Psi = np.zeros(50)
Psi.fill(0.04)
#print '*******', len(Psi)



#print tau
plt.figure(1)
plt.plot(tau,Psi)
#plt.show()

'''COMPUTING THE CONTINUUM FUNCTION FOR REQUIRED POINTS'''
pts_required=len(rvm_spectra_date)*len(tau)
interpolation_points = np.empty([len(rvm_spectra_date),len(tau)])
#print interpolation_points.shape
q=0
for idate in range(0,len(rvm_spectra_date)):
	for jdelay in range(0,len(tau)):
		interpolation_points[idate][jdelay] = rvm_spectra_date[idate]-tau[jdelay]
#f= interp1d(continuum_date,continuum_flux)					#Creates interpolation function
f= UVS(continuum_date,continuum_flux,k=1)					#Creates interpolation function
ICF = f(np.ravel(interpolation_points))			#Interpolates continuum over points
ICF=np.reshape(ICF,(len(rvm_spectra_date),len(tau)))
int_continuum_dates = interpolation_points					#only to make a matching set

#print "REGULAR: ",interpolation_points
#print "RAVELED: ",np.ravel(interpolation_points)

#INTERPOLATION!!!
#f= interp1d(continuum_date,continuum_flux)  
#f = interp1d(data[0,:],data[1,:],bounds_error=False,fill_value=data[65,2])
#ICF = f(data_flux_dates)
#ICF[impulse_position]=impulse_value
print 'ICF: ', ICF

L = Model(Psi,ICF)
LR=L
percent_err = 0.0
for j in range(0,len(data_errflux)):
	for h in range(0,len(L)):
		#data_flux[j][h]=np.random.normal(L[h],0.02*L[h])
		data_flux[j][h] = L[h] #USING NO NOISE FOR TESTING!
	data_errflux[j] = 1.0 #MAKE SIGMA AS SIMPLE AS POSSIBLE FOR TESTING!	
	#data_errflux[j] = percent_err/100*L
print data.shape

TDF = np.array([tau,Psi])
#print TDF
np.savetxt('rvm_flxS.csv',data_flux,delimiter=',')
print "Wrote: rvm_flxS.csv"
np.savetxt('rvm_flx_errS.csv',data_errflux,delimiter=',')	
print "Wrote: rvm_flx_errS.csv"
np.savetxt('continuumS.csv',data,delimiter=',')
print "Wrote: continuumS.csv"
np.savetxt('PsiS.txt',TDF,delimiter=',')

plt.figure(2)
#plt.plot(data_flux_dates,L)
plt.plot(data_flux[0])
plt.plot(L,'r--')
#plt.figure()
#plt.plot(data[:,1])
plt.show()

#print data[:,1]
